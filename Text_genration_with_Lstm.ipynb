{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvTlwuatHORm",
        "outputId": "9ba2e57d-05d4-489e-dfcd-b44fc1f376d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Tensorflow_2\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "%cd 'drive/MyDrive/Tensorflow_2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlYXHwZeQ9ce"
      },
      "outputs": [],
      "source": [
        "import functions as f\n",
        "\n",
        "from Text import *\n",
        "from LSTM_class import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras import layers, models, optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3ayxDyoOO-T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCsPc173IHHA"
      },
      "outputs": [],
      "source": [
        "path_train = '/content/drive/MyDrive/Tensorflow_2/merged_clean.txt'\n",
        "\n",
        "input_train = f.read_txt(path_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWnw1H91PPr8",
        "outputId": "af694e3b-a7a5-4467-b54a-d8b8ccf66310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total tokens: 2734890, distinct tokens: 41044\n",
            "number of sequences of length 4: 911629\n"
          ]
        }
      ],
      "source": [
        "max_len = 4\n",
        "step = 3\n",
        "\n",
        "text_train = Text(input_train)\n",
        "text_train.tokens_info()\n",
        "\n",
        "seq_train = Sequences(text_train, max_len, step)\n",
        "seq_train.sequences_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR8AWElrPtA8",
        "outputId": "b07aefb6-69d0-4fc8-ed5d-8d7134b17521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Lovely', 'IlonkaThere', 'was', 'once', 'a', \"king's\", 'son', 'who', 'told', 'his']\n",
            "[32030, 36371, 5124, 16854, 24911, 28905, 14370, 1863, 21176, 15055] \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[32030, 36371,  5124, 16854],\n",
              "       [16854, 24911, 28905, 14370]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(text_train.tokens[:10])\n",
        "print(text_train.tokens_ind[:10], '\\n')\n",
        "\n",
        "np.array(seq_train.sequences[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Zwi31NjP1Az"
      },
      "outputs": [],
      "source": [
        "batch_size = 4096\n",
        "\n",
        "params = {\n",
        "  'sequence_length': max_len,\n",
        "  'vocab_size': len(text_train),\n",
        "  'batch_size': batch_size,\n",
        "  'shuffle': True\n",
        "}\n",
        "\n",
        "train_generator = TextDataGenerator(seq_train.sequences, seq_train.next_words, **params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Wm46hJdP7Ba"
      },
      "outputs": [],
      "source": [
        "def lstm_model(sequence_length, vocab_size, layer_size, embedding=False):\n",
        "  model = models.Sequential()\n",
        "  if embedding:\n",
        "    model.add(layers.Embedding(vocab_size, layer_size))\n",
        "    model.add(layers.LSTM(layer_size))    \n",
        "  else:\n",
        "    model.add(layers.LSTM(layer_size, input_shape=(sequence_length, vocab_size)))\n",
        "  model.add(layers.Dropout(0.3))\n",
        "  model.add(layers.Dense(vocab_size, activation='softmax'))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIPmU3VsQAtH",
        "outputId": "520d8d16-2a09-4a78-b35e-0e339a6511cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = lstm_model(max_len, len(text_train), 512)\n",
        "\n",
        "optimizer = optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWhaSNmlQE0C",
        "outputId": "5f83158f-2d5d-4344-ced0-adf84fc05288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "222/222 [==============================] - 593s 3s/step - loss: 5.9282\n",
            "Epoch 2/2\n",
            "183/222 [=======================>......] - ETA: 1:43 - loss: 4.9188"
          ]
        }
      ],
      "source": [
        "model.fit(train_generator,\n",
        "          steps_per_epoch=len(train_generator),\n",
        "          epochs=2,\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ08rAZOQMWb"
      },
      "outputs": [],
      "source": [
        "model.save('data/out/lstm_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAfJ_oX1RjJP"
      },
      "source": [
        "#Text generation with LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_LpE2GcRkcL"
      },
      "outputs": [],
      "source": [
        "token2ind, ind2token = text_train.token2ind, text_train.ind2token\n",
        "\n",
        "input_prefix = 'Once upon a time'\n",
        "text_prefix = Text(input_prefix, token2ind, ind2token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJKPdPLPRqK2"
      },
      "outputs": [],
      "source": [
        "pred = ModelPredict(model, text_prefix, token2ind, ind2token, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YE9LEE3_RqOC"
      },
      "outputs": [],
      "source": [
        "temperatures = [1, 0.7, 0.4, 0.1]\n",
        "\n",
        "for temperature in temperatures:\n",
        "  print('temperature:', temperature)\n",
        "  print(pred.generate_sequence(100, temperature=0.7))\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q93ccBc2R347"
      },
      "source": [
        "#Text generation with LSTM model with Embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTgUJvjBR5Dl"
      },
      "outputs": [],
      "source": [
        "batch_size_emb = 4096\n",
        "\n",
        "params_emb = params.copy()\n",
        "params_emb['embedding'] = True\n",
        "\n",
        "train_generator_emb = TextDataGenerator(seq_train.sequences, seq_train.next_words, **params_emb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e53c9UtsR88I"
      },
      "outputs": [],
      "source": [
        "model_emb = lstm_model(max_len, len(text_train), 512, embedding=True)\n",
        "model_emb.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZZEe4KkIR8_K",
        "outputId": "cdf77fd5-2678-4d82-a81b-7ae8c5e0857d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "222/222 [==============================] - 113s 508ms/step - loss: 5.2527\n",
            "Epoch 2/40\n",
            "222/222 [==============================] - 112s 503ms/step - loss: 4.8233\n",
            "Epoch 3/40\n",
            "222/222 [==============================] - 113s 505ms/step - loss: 4.6237\n",
            "Epoch 4/40\n",
            "222/222 [==============================] - 112s 504ms/step - loss: 4.4655\n",
            "Epoch 5/40\n",
            "222/222 [==============================] - 113s 506ms/step - loss: 4.3315\n",
            "Epoch 6/40\n",
            "222/222 [==============================] - 115s 516ms/step - loss: 4.2182\n",
            "Epoch 7/40\n",
            "222/222 [==============================] - 115s 516ms/step - loss: 4.1238\n",
            "Epoch 8/40\n",
            "222/222 [==============================] - 115s 517ms/step - loss: 4.0378\n",
            "Epoch 9/40\n",
            "222/222 [==============================] - 115s 517ms/step - loss: 3.9649\n",
            "Epoch 10/40\n",
            "222/222 [==============================] - 115s 515ms/step - loss: 3.9033\n",
            "Epoch 11/40\n",
            "222/222 [==============================] - 114s 514ms/step - loss: 3.8513\n",
            "Epoch 12/40\n",
            "222/222 [==============================] - 115s 517ms/step - loss: 3.8080\n",
            "Epoch 13/40\n",
            "222/222 [==============================] - 116s 519ms/step - loss: 3.7704\n",
            "Epoch 14/40\n",
            "222/222 [==============================] - 114s 514ms/step - loss: 3.7364\n",
            "Epoch 15/40\n",
            "222/222 [==============================] - 115s 516ms/step - loss: 3.7081\n",
            "Epoch 16/40\n",
            "222/222 [==============================] - 115s 515ms/step - loss: 3.6865\n",
            "Epoch 17/40\n",
            "222/222 [==============================] - 115s 517ms/step - loss: 3.6726\n",
            "Epoch 18/40\n",
            "222/222 [==============================] - 115s 517ms/step - loss: 3.6549\n",
            "Epoch 19/40\n",
            "222/222 [==============================] - 115s 517ms/step - loss: 3.6439\n",
            "Epoch 20/40\n",
            "222/222 [==============================] - 115s 517ms/step - loss: 3.6340\n",
            "Epoch 21/40\n",
            "222/222 [==============================] - 115s 516ms/step - loss: 3.6322\n",
            "Epoch 22/40\n",
            "222/222 [==============================] - 115s 518ms/step - loss: 3.6244\n",
            "Epoch 23/40\n",
            "222/222 [==============================] - 115s 516ms/step - loss: 3.6219\n",
            "Epoch 24/40\n",
            "222/222 [==============================] - 114s 512ms/step - loss: 3.6193\n",
            "Epoch 25/40\n",
            "222/222 [==============================] - 115s 515ms/step - loss: 3.6202\n",
            "Epoch 26/40\n",
            "222/222 [==============================] - 115s 517ms/step - loss: 3.6210\n",
            "Epoch 27/40\n",
            "222/222 [==============================] - 115s 516ms/step - loss: 3.6193\n",
            "Epoch 28/40\n",
            "222/222 [==============================] - 115s 516ms/step - loss: 3.6214\n",
            "Epoch 29/40\n",
            "222/222 [==============================] - 115s 517ms/step - loss: 3.6242\n",
            "Epoch 30/40\n",
            "222/222 [==============================] - 115s 516ms/step - loss: 3.6319\n",
            "Epoch 31/40\n",
            "222/222 [==============================] - 115s 517ms/step - loss: 3.6362\n",
            "Epoch 32/40\n",
            "222/222 [==============================] - 115s 517ms/step - loss: 3.6382\n",
            "Epoch 33/40\n",
            "222/222 [==============================] - 115s 515ms/step - loss: 3.6463\n",
            "Epoch 34/40\n",
            "222/222 [==============================] - 115s 518ms/step - loss: 3.6531\n",
            "Epoch 35/40\n",
            "222/222 [==============================] - 117s 523ms/step - loss: 3.6558\n",
            "Epoch 36/40\n",
            "222/222 [==============================] - 117s 526ms/step - loss: 3.6629\n",
            "Epoch 37/40\n",
            "222/222 [==============================] - 117s 527ms/step - loss: 3.6698\n",
            "Epoch 38/40\n",
            "222/222 [==============================] - 118s 529ms/step - loss: 3.6762\n",
            "Epoch 39/40\n",
            "222/222 [==============================] - 118s 528ms/step - loss: 3.6840\n",
            "Epoch 40/40\n",
            "222/222 [==============================] - 117s 527ms/step - loss: 3.6894\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0a8af01910>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_emb.fit(train_generator_emb,\n",
        "              steps_per_epoch=len(train_generator_emb),\n",
        "              epochs=40,\n",
        "              verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCzN3TC_R9El"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_emb.save('data/out/lstm_model_emb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aqa2rfzjSKu7"
      },
      "outputs": [],
      "source": [
        "pred_emb = ModelPredict(model_emb, text_prefix, token2ind, ind2token, max_len, embedding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRTrvjqbSKyA"
      },
      "outputs": [],
      "source": [
        "temperatures = [1, 0.7, 0.4, 0.1]\n",
        "\n",
        "for temperature in temperatures:\n",
        "  print('temperature:', temperature)\n",
        "  print(pred_emb.generate_sequence(100, temperature=0.7))\n",
        "  print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofJyjXmiR9Hu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}